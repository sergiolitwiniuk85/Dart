{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiolitwiniuk85/Dart/blob/main/variant_calling_genome_dart_fixed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Llamado de Variantes Completo para *Ilex paraguariensis* desde archivos FASTQ.gz**\n",
        "\n",
        "Este Jupyter Notebook describe un flujo de trabajo completo para la identificación de variantes genéticas (SNPs y pequeños INDELs)\n",
        "en datos de secuenciación DART de *Ilex paraguariensis*, comenzando desde los archivos FASTQ.gz.\n",
        "*Ilex paraguariensis* corresponde a un organismo diploide.\n",
        "* Se seguirán las buenas prácticas recomendadas para el análisis genómico de plantas.\n",
        "\n",
        "**Requisitos Previos:**\n",
        "\n",
        "1.  **Instalación de Herramientas:**: para ello crearemos un ambiente virtual en conda\n",
        "    \n",
        "    *   **fastqwiper**: para la correccion inicil de los archivos fastq corruptos que ya he identificado previamente.\n",
        "    *   **fastp**: Para el preprocesamiento de las lecturas FASTQ (trimming de calidad y eliminación de adaptadores). (Este no se menciona directamente en las fuentes para plantas, pero es una buena práctica común).\n",
        "    *   **BWA (Burrows-Wheeler Aligner)**: Para alinear las lecturas de secuenciación al genoma de referencia.\n",
        "    *   **SAMtools**: Para manipular archivos en formato SAM/BAM (formato de alineación).\n",
        "    *   **Picard Tools**: Para el manejo de archivos BAM, incluyendo la marcación de duplicados.\n",
        "    *   **GATK (Genome Analysis Toolkit) [link text](https://gatk.broadinstitute.org/hc/en-us/articles/360035889851--How-to-Install-and-use-Conda-for-GATK4)**: Para el llamado de variantes, recalibración de calidad base y genotipado conjunto.\n",
        "\n",
        "\n",
        "2.  **Genoma de Referencia de *Ilex paraguariensis*:** Archivo del genoma de referencia de *Ilex paraguariensis* en formato FASTA `ilex_paraguariensis_ref.fasta`) y archivo de índice para BWA (generado previamente con `bwa index`).\n",
        "\n",
        "2.  **Transcriptoma de Referencia de *Ilex paraguariensis*:** Archivo del genoma de referencia de *Ilex paraguariensis* en formato FASTA.\n",
        "\n",
        "3.  **Archivo de Nombres de Muestras:** Un archivo de texto (como \"archivos\\_muestras\\_ilex\\_paraguariensis - Hoja1.txt\") que contenga la lista de nombres de tus archivos FASTQ.gz. Los archivos secuenciados provienen de una secuenciacion single-end.\n",
        "\n",
        "**Configuración de Rutas y Variables:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Antes de comenzar nos aseguramos de tener un entorno con todas las dependencias funcionando, para eso creo al archivo environment.yml con nano, y agrego los siguientes requerimientos:\n",
        "```\n",
        "name: dartcalling\n",
        "channels:\n",
        "  - conda-forge\n",
        "  - bioconda\n",
        "  - defaults\n",
        "  - bfxcss\n",
        "dependencies:\n",
        "  - bwa-mem2  # Una versión más moderna y recomendada de BWA\n",
        "  - samtools\n",
        "  - picard  # Picard suele instalarse como un paquete\n",
        "  - gatk4   # La última versión de GATK\n",
        "  - fastp\n",
        "  - python=3.x  # Especifica la versión de Python que necesitas (ej: 3.9, 3.10)\n",
        "  - fastqwiper\n",
        "```\n",
        "\n",
        "Creo el entorno nuevo:\n",
        "```\n",
        "conda env create -f environment.yml\n",
        "```\n",
        "Activo el entorno:\n",
        "```\n",
        "conda activate dartcalling\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5hdlkETzNTWK"
      },
      "id": "5hdlkETzNTWK"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Crear grafico del pipeline,\n",
        "con mermaid,\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J7PKAEa7DRnl",
        "outputId": "8d1a284f-e19c-4636-ef7b-43abdb2cbe15"
      },
      "id": "J7PKAEa7DRnl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCrear grafico del pipeline,\\ncon mermaid,\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "021bd364",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "collapsed": true,
        "id": "021bd364",
        "outputId": "2a0f5f15-0e72-4bd8-a6e6-c9730a56d6c9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated triple-quoted string literal (detected at line 289) (<ipython-input-2-c06bebcd53de>, line 289)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-c06bebcd53de>\"\u001b[0;36m, line \u001b[0;32m289\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 289)\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Define las rutas a las herramientas y archivos de referencia\n",
        "bwa_path = \"bwa\"  # Asegúrate de que BWA esté en tu PATH o especifica la ruta completa\n",
        "samtools_path = \"samtools\" # Asegúrate de que SAMtools esté en tu PATH o especifica la ruta completa\n",
        "picard_path = \"picard\"    # Especifica la ruta al directorio de Picard Tools (ej: /path/to/picard.jar)\n",
        "gatk_path = \"gatk\"        # Asegúrate de que GATK esté en tu PATH o especifica la ruta completa\n",
        "fastp_path = \"fastp\"      # Asegúrate de que fastp esté en tu PATH o especifica la ruta completa\n",
        "\n",
        "reference_genome = \"ilex_paraguariensis_ref.fasta\" # Reemplaza con la ruta a tu genoma de referencia\n",
        "reference_index = \"ilex_paraguariensis_ref.fasta.fai\" # BWA genera índices con el mismo prefijo\n",
        "\n",
        "fastq_dir = \"./fastq_files\" # Directorio donde se encuentran tus archivos FASTQ.gz\n",
        "sample_list_file = \"archivos_muestras_ilex_paraguariensis - Hoja1.txt\"\n",
        "output_dir = \"./variant_calling_output\"\n",
        "\n",
        "# Asegúrate de que el directorio de salida exista\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Lee la lista de nombres de muestra desde el archivo\n",
        "try:\n",
        "    with open(sample_list_file, 'r') as f:\n",
        "        sample_names = [line.strip() for line in f]\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: El archivo de lista de muestras '{sample_list_file}' no fue encontrado.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Lista de muestras a procesar:\", sample_names)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bucle Principal para el Procesamiento de Cada Muestra:**\n",
        "\n",
        "El siguiente bucle iterará a través de cada nombre de muestra en la lista y ejecutará los pasos\n",
        "de preprocesamiento, alineación, marcación de duplicados y llamado de variantes para cada muestra individualmente.\n"
      ],
      "metadata": {
        "id": "ARJi1szkPY5r"
      },
      "id": "ARJi1szkPY5r"
    },
    {
      "cell_type": "code",
      "source": [
        "for sample_name in sample_names:\n",
        "    print(f\"\\n**Procesando muestra: {sample_name}**\")\n",
        "\n",
        "    # Define el nombre del archivo FASTQ para la muestra actual (Single-end)\n",
        "    fastq = os.path.join(fastq_dir, f\"{sample_name}.fastq.gz\")\n",
        "\n",
        "    if not os.path.exists(fastq):\n",
        "        print(f\"Advertencia: Archivo FASTQ no encontrado para la muestra '{sample_name}'. Saltando esta muestra.\")\n",
        "        continue\n",
        "\n",
        "    # Define los nombres de los archivos de salida para esta muestra\n",
        "    trimmed_fastq = os.path.join(output_dir, f\"{sample_name}_trimmed.fastq.gz\")\n",
        "    sam_file = os.path.join(output_dir, f\"{sample_name}.sam\")\n",
        "    bam_file = os.path.join(output_dir, f\"{sample_name}.bam\")\n",
        "    sorted_bam_file = os.path.join(output_dir, f\"{sample_name}_sorted.bam\")\n",
        "    marked_duplicates_bam = os.path.join(output_dir, f\"{sample_name}_mkdup.bam\")\n",
        "    metrics_file = os.path.join(output_dir, f\"{sample_name}_metrics.txt\")\n",
        "    gvcf_file = os.path.join(output_dir, f\"{sample_name}.g.vcf.gz\")\n",
        "\n",
        "    \"\"\"\n",
        "    **Paso 1: Preprocesamiento de Lecturas FASTQ con fastp**\n",
        "\n",
        "    Este paso realiza el trimming de calidad, eliminación de adaptadores y trimming de las primeras 19 bases.\n",
        "    \"\"\"\n",
        "    print(\"  - Ejecutando fastp para trimming...\")\n",
        "    fastp_command = [\n",
        "        fastp_path,\n",
        "        \"-i\", fastq,\n",
        "        \"-o\", trimmed_fastq,\n",
        "        \"--trim_front1\", \"19\",\n",
        "        \"-q\", \"30\",\n",
        "        \"-u\", \"20\",\n",
        "        \"-n\", \"5\",\n",
        "        \"--length_required\", \"50\",\n",
        "        \"-h\", os.path.join(output_dir, f\"{sample_name}_fastp.html\"),\n",
        "        \"-j\", os.path.join(output_dir, f\"{sample_name}_fastp.json\")\n",
        "    ]\n",
        "    subprocess.run(fastp_command, check=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    **Paso 2: Alineación de Lecturas al Genoma de Referencia con BWA-MEM**\n",
        "    \"\"\"\n",
        "    print(\"  - Alineando lecturas con BWA-MEM...\")\n",
        "    bwa_mem_command = [\n",
        "        bwa_path, \"mem\",\n",
        "        \"-t\", \"30\",                   # Threads\n",
        "        \"-k\", \"19\",                   # Minimum seed length (default)\n",
        "        \"-c\", \"50000\",              # Increase max occurrences (vs default 10,000)\n",
        "        \"-R\", f\"@RG\\\\tID:{sample_name}\\\\tSM:{sample_name}\",  # Read group\n",
        "        reference_genome,\n",
        "        trimmed_fastq\n",
        "    ]\n",
        "    with open(sam_file, \"w\") as outfile:\n",
        "        subprocess.run(bwa_mem_command, stdout=outfile, check=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    **Paso 3: Conversión de SAM a BAM y Ordenamiento con SAMtools**\n",
        "    \"\"\"\n",
        "    print(\"  - Convirtiendo SAM a BAM y ordenando...\")\n",
        "    samtools_view_command = [samtools_path, \"view\", \"-bS\", sam_file]\n",
        "    with open(bam_file, \"wb\") as outfile:\n",
        "        subprocess.run(samtools_view_command, stdout=outfile, check=True)\n",
        "\n",
        "    samtools_sort_command = [samtools_path, \"sort\", \"-o\", sorted_bam_file, bam_file]\n",
        "    subprocess.run(samtools_sort_command, check=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    **Paso 4: Indexación del Archivo BAM Ordenado con SAMtools**\n",
        "    \"\"\"\n",
        "    print(\"  - Indexando archivo BAM ordenado...\")\n",
        "    samtools_index_command = [samtools_path, \"index\", sorted_bam_file]\n",
        "    subprocess.run(samtools_index_command, check=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    **Paso 5: Marcación de Duplicados PCR con Picard MarkDuplicates**\n",
        "    \"\"\"\n",
        "    print(\"  - Marcando duplicados PCR con Picard...\")\n",
        "    mark_duplicates_command = [\n",
        "        \"java\", \"-Xmx8G\", \"-jar\", picard_path, \"MarkDuplicates\",\n",
        "        \"-I\", sorted_bam_file,\n",
        "        \"-O\", marked_duplicates_bam,\n",
        "        \"-M\", metrics_file,\n",
        "        \"--REMOVE_DUPLICATES\", \"false\",          # Critical for SNP calling\n",
        "        \"--ASSUME_SORT_ORDER\", \"coordinate\",     # Required for coordinate-sorted BAMs\n",
        "        \"--OPTICAL_DUPLICATE_PIXEL_DISTANCE\", \"100\", # NovaSeq/HiSeqX settings(e.g., HiSeq 2000/2500, MiSeq, NextSeq 500) or a non-Illumina platform,\n",
        "                                                      # you might need a different value (e.g., 100 is often default for older platforms,\n",
        "                                                      # or even 0 to disable if read names don't contain coordinate info)\n",
        "        \"--CREATE_INDEX\", \"true\",                # Required for GATK\n",
        "        \"--VALIDATION_STRINGENCY\", \"STRICT\",     # Ensures BAM compliance\n",
        "    ]\n",
        "    subprocess.run(mark_duplicates_command, check=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    **Paso 6: Indexación del Archivo BAM con Duplicados Marcados con SAMtools**\n",
        "    \"\"\"\n",
        "    print(\"  - Indexando archivo BAM con duplicados marcados...\")\n",
        "    samtools_index_command = [samtools_path, \"index\", marked_duplicates_bam]\n",
        "    subprocess.run(samtools_index_command, check=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    **Paso 7: Llamado de Variantes con GATK HaplotypeCaller en Modo GVCF**\n",
        "    \"\"\"\n",
        "    print(\"  - Llamando variantes con GATK HaplotypeCaller (modo GVCF)...\")\n",
        "\n",
        "    haplotype_caller_command = [\n",
        "    gatk_path, \"HaplotypeCaller\",\n",
        "    \"-R\", reference_genome,                      # Reference genome (must be indexed)\n",
        "    \"-I\", marked_duplicates_bam,                 # Input BAM (marked duplicates)\n",
        "    \"-O\", gvcf_file,                             # Output GVCF\n",
        "    \"-ERC\", \"GVCF\",                              # Enable GVCF output\n",
        "    \"--ploidy\", \"2\",                             # Diploid organisms\n",
        "    \"--native-pair-hmm-threads\", \"8\",            # Optimize CPU usage\n",
        "    \"--minimum-mapping-quality\", \"20\",           # Filter low-confidence reads\n",
        "    \"--dont-use-soft-clipped-bases\", \"true\",     # Avoid false positives\n",
        "    \"--standard-min-confidence-threshold-for-calling\", \"30\",  # Min quality for variants\n",
        "    \"--max-reads-per-alignment-start\", \"500\",     # Reduce noise in deep regions\n",
        "    \"--max-effective-depth\", \"2000\",  # Prevents over-processing ultra-deep regions\n",
        "\n",
        "    \"--max-alternate-alleles\", \"3\",              # Limit complex loci\n",
        "\n",
        "    \"--disable-read-filter\", \"NotDuplicateReadFilter\",  # DArT markers may amplify duplicates\n",
        "    \"--native-pair-hmm-threads\", \"4\",  # Fewer threads to prevent memory issues\n",
        "\n",
        "    \"--annotation-group\", \"StandardAnnotation\",   # Standard annotations\n",
        "    \"--annotation\", \"MappingQualityRankSumTest\",  # Additional QC\n",
        "    \"--annotation\", \"ReadPosRankSumTest\",\n",
        "    \"--emit-ref-confidence\", \"GVCF\",             # Required for joint genotyping\n",
        "    \"--bam-output\", f\"{sample_name}_realigned.bam\",  # Optional: debug realignments\n",
        "    ]\n",
        "    subprocess.run(haplotype_caller_command, check=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "kl3DIVkDPb_5",
        "outputId": "187707ed-9a7b-4fd6-fe85-dba9ed576c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "id": "kl3DIVkDPb_5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sample_names' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6f0866d50f83>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msample_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n**Procesando muestra: {sample_name}**\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Define el nombre del archivo FASTQ para la muestra actual (Single-end)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfastq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfastq_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{sample_name}.fastq.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_names' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CyhrfPIAT7hu"
      },
      "id": "CyhrfPIAT7hu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paso 8: Genotipado Conjunto con GATK GenotypeGVCFs**\n",
        "\n",
        "Después de generar archivos GVCF para cada muestra individual, este paso realiza el genotipado conjunto.\n",
        "Esto refina las llamadas de variantes al considerar la información de todas las muestras simultáneamente."
      ],
      "metadata": {
        "id": "stv1B1RZP0Jw"
      },
      "id": "stv1B1RZP0Jw"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n**Realizando Genotipado Conjunto con GATK GenotypeGVCFs...**\")\n",
        "\n",
        "gvcf_files_for_joint_genotyping = [os.path.join(output_dir, f\"{name}.g.vcf.gz\") for name in sample_names if os.path.exists(os.path.join(output_dir, f\"{name}.g.vcf.gz\"))]\n",
        "\n",
        "if not gvcf_files_for_joint_genotyping:\n",
        "    print(\"Advertencia: No se encontraron archivos GVCF para realizar el genotipado conjunto.\")\n",
        "else:\n",
        "   joint_genotyping_command = [\n",
        "    \"java\", \"-Xmx16G\", \"-jar\", gatk_path, \"GenotypeGVCFs\",\n",
        "    \"-R\", reference_genome,\n",
        "    \"-O\", os.path.join(output_dir, \"raw_variants.vcf.gz\"),\n",
        "    \"--tmp-dir\", \"/path/to/large_tmp\",  # Critical for large datasets\n",
        "    \"--allow-old-rms-mapping-quality-annotation-data\",  # For compatibility\n",
        "    \"--standard-min-confidence-threshold-for-calling\", \"30\",\n",
        "\n",
        "    # DArT-specific adjustments:\n",
        "    \"--max-alternate-alleles\", \"6\",  # Increased for potential multi-allelic sites\n",
        "    \"--include-non-variant-sites\", \"false\",  # Skip reference sites (already in GVCFs)\n",
        "    \"--annotate-with-num-discovered-alleles\",  # Helps with multi-sample analysis\n",
        "\n",
        "    # Performance optimizations:\n",
        "]\n",
        "\n",
        "# Add all GVCFs to the command\n",
        "for gvcf_file in gvcf_files_for_joint_genotyping:\n",
        "    joint_genotyping_command.extend([\"-V\", gvcf_file])\n",
        "\n",
        "subprocess.run(joint_genotyping_command, check=True)\n",
        "\n",
        "    \"\"\"\n",
        "    **Paso 9: Filtrado Duro de Variantes con GATK VariantFiltration**\n",
        "\n",
        "    Este paso aplica filtros básicos (\"duros\") basados en varias anotaciones de calidad de las variantes\n",
        "    para eliminar posibles falsos positivos. Los umbrales de filtrado pueden necesitar ser ajustados\n",
        "    dependiendo de las características específicas del conjunto de datos y el organismo.\n",
        "    Los siguientes filtros son sugerencias basadas en prácticas comunes:\n",
        "\n",
        "    *   Para SNPs:\n",
        "        *   `QD < 2.0`: Calidad del sitio dividida por la profundidad de lectura.\n",
        "        *   `FS > 60.0`: Fisher Strand, mide el sesgo de hebra.\n",
        "        *   `MQ < 40.0`: Calidad de mapeo RMS.\n",
        "        *   `SOR > 3.0`: StrandOddsRatio, otra medida de sesgo de hebra.\n",
        "\n",
        "    *   Para INDELs:\n",
        "        *   `QD < 2.0`\n",
        "        *   `FS > 200.0`\n",
        "        *   `ReadPosRankSum < -20.0`: Prueba de suma de rangos de posición de lectura.\n",
        "    \"\"\"\n",
        "    print(\"\\n**Aplicando Filtrado Duro de Variantes con GATK VariantFiltration...**\")\n",
        "\n",
        "    raw_variants_vcf = os.path.join(output_dir, \"raw_variants.vcf.gz\")\n",
        "    filtered_snps_vcf = os.path.join(output_dir, \"filtered_snps.vcf.gz\")\n",
        "    filtered_indels_vcf = os.path.join(output_dir, \"filtered_indels.vcf.gz\")\n",
        "    final_filtered_vcf = os.path.join(output_dir, \"final_variants.vcf.gz\")\n",
        "\n",
        "    # Filtrado de SNPs\n",
        "    filter_snps_command = [\n",
        "        gatk_path, \"VariantFiltration\",\n",
        "        \"-R\", reference_genome,\n",
        "        \"-V\", raw_variants_vcf,\n",
        "        \"-O\", filtered_snps_vcf,\n",
        "        \"--filter-expression\", \"QD < 2.0 || FS > 60.0 || MQ < 40.0 || SOR > 3.0\",\n",
        "        \"--filter-name\", \"snp_filter\"\n",
        "    ]\n",
        "    subprocess.run(filter_snps_command, check=True)\n",
        "\n",
        "    # Filtrado de INDELs\n",
        "    filter_indels_command = [\n",
        "        gatk_path, \"VariantFiltration\",\n",
        "        \"-R\", reference_genome,\n",
        "        \"-V\", filtered_snps_vcf,  # Se filtra sobre el resultado del filtrado de SNPs\n",
        "        \"-O\", filtered_indels_vcf,\n",
        "        \"--filter-expression\", \"QD < 2.0 || FS > 200.0 || ReadPosRankSum < -20.0\",\n",
        "        \"--filter-name\", \"indel_filter\"\n",
        "    ]\n",
        "    subprocess.run(filter_indels_command, check=True)\n",
        "\n",
        "    # Unir SNPs e INDELs filtrados (esto es una forma sencilla, puede haber mejores estrategias)\n",
        "    # Se recomienda evaluar los resultados de forma separada antes de combinarlos.\n",
        "    # Para este ejemplo, simplemente renombramos el archivo de INDELs filtrados como el resultado final.\n",
        "    os.rename(filtered_indels_vcf, final_filtered_vcf)\n",
        "\n",
        "    # Indexar el archivo VCF final\n",
        "    index_vcf_command = [gatk_path, \"IndexFeatureFile\", \"-F\", final_filtered_vcf]\n",
        "    subprocess.run(index_vcf_command, check=True)\n",
        "\n",
        "    print(f\"\\n**Flujo de trabajo completado. El archivo VCF final se encuentra en: {final_filtered_vcf}**\")\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "dcMMEdxRP0gQ"
      },
      "id": "dcMMEdxRP0gQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consideraciones Adicionales y Buenas Prácticas para Genomas de Plantas:**\n",
        "\n",
        "*   **Calidad del Genoma de Referencia:** La precisión del llamado de variantes depende en gran medida de la calidad y completitud del genoma de referencia.\n",
        "*   **Regiones Repetitivas y Variaciones Estructurales (SVs):** Los genomas de plantas a menudo contienen grandes cantidades de secuencias repetitivas y variaciones estructurales. Los flujos de trabajo estándar de llamado de SNPs pueden tener dificultades en estas regiones. Se pueden requerir herramientas y estrategias específicas para la detección de SVs (como DELLY, Lumpy, Manta).\n",
        "*   **Ploidy:** Se ha especificado `-ploidy 2` para *Ilex paraguariensis*.\n",
        "*   **Recalibración de Calidad Base (BQSR):** En organismos no humanos sin conjuntos de variantes conocidos, se puede realizar un \"bootstrap\" para generar un conjunto de variantes de alta confianza para usar en la BQSR. Esto implicaría una ronda inicial de llamado de variantes, filtrado estricto de las variantes con mayor confianza y luego usar ese conjunto para la BQSR y un nuevo llamado de variantes. Esto podría mejorar la precisión de las llamadas de variantes.\n",
        "*   **Filtrado Avanzado (Machine Learning):** La fuente menciona el uso de métodos de filtrado basados en aprendizaje automático, como GATK VariantRecalibrator. Estos métodos utilizan conjuntos de variantes conocidos de alta calidad para entrenar un modelo y luego aplicar filtros adaptativos. Si se dispone de un conjunto de variantes de alta confianza para *Ilex paraguariensis*, se podría considerar este enfoque para un filtrado más preciso.\n",
        "*   **Pan-genomas:** Si existe un pan-genoma de *Ilex paraguariensis* o especies relacionadas, podría ser útil para detectar \"diversidad oculta\" debido a variaciones de presencia/ausencia (PAVs).\n",
        "*   **Validación:** Las variantes identificadas deben validarse experimentalmente siempre que sea posible, especialmente aquellas de importancia biológica o clínica.\n",
        "\n",
        "Este notebook proporciona un punto de partida sólido para el llamado de variantes. La optimización de los parámetros y la incorporación de pasos más avanzados como la BQSR y el filtrado basado en aprendizaje automático pueden mejorar aún más la precisión de los resultados."
      ],
      "metadata": {
        "id": "Hhj_8zNzRQzf"
      },
      "id": "Hhj_8zNzRQzf"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DDzc8otORUb0"
      },
      "id": "DDzc8otORUb0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b8Rfd60IRpVc"
      },
      "id": "b8Rfd60IRpVc",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}